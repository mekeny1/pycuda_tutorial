-----------------------------------------------------------
Starting training epoch: 0
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 1
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 2
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 3
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 4
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 5
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 6
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 7
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 8
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 9
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 10
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 11
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 12
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 13
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 14
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 15
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 16
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 17
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 18
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 19
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 20
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 21
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 22
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 23
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 24
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 25
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 26
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 27
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 28
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 29
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 30
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 31
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 32
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 33
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 34
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 35
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 36
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 37
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 38
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 39
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 40
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 41
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 42
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 43
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 44
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 45
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 46
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 47
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 48
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 49
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 50
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 51
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 52
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 53
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 54
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 55
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 56
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 57
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 58
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 59
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 60
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 61
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 62
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 63
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 64
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 65
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 66
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 67
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 68
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 69
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 70
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 71
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 72
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 73
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 74
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 75
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 76
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 77
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 78
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 79
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 80
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 81
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 82
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 83
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 84
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 85
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 86
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 87
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 88
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 89
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 90
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 91
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 92
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 93
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 94
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 95
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 96
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 97
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 98
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
-----------------------------------------------------------
Starting training epoch: 99
Batch size: 16 , Total number of training samples: 100
-----------------------------------------------------------
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
entropy: 0.6036434153395501
Percentage Correct Classifications: 0.44
Total Training Time: 440.106160402298
